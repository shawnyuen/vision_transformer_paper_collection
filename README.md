# vision_transformer_paper_collection

## Survey or Review
### A Survey on Vision Transformer IEEE TPAMI 2023 [[paper]](https://ieeexplore.ieee.org/document/9716741)

## 2023
### DilateFormer Multi-Scale Dilated Transformer for Visual Recognition IEEE TMM 2023 [[paper]](https://arxiv.org/abs/2302.01791) [[code]](https://github.com/JIAOJIAYUASD/dilateformer)
### EfficientViT - Memory Efficient Vision Transformer with Cascaded Group Attention CVPR 2023 [[paper]](https://arxiv.org/abs/2305.07027)
### Full Contextural Attention for MUlti-resolution Transformers in Semantic Segmentation IEEE WACV 2023s
### LipsFormer - Introducing Lipschitz Continuity to Vision Transformers ICLR 2023 [[paper]](https://arxiv.org/abs/2304.09856)
### (STViT) Making Vision Transformers Efficient from A Token Sparsification View CVPR 2023 [[paper]](https://arxiv.org/abs/2303.08685)
### ShadowFormer Global Context Helps Image Shadow Removal AAAI 2023 [[paper]](https://arxiv.org/abs/2302.01650)
### SwiftFormer - Efficient Additive Attention for Transformer-based Real-time Mobile Vision Applications arXiv 2023 [[paper]](https://arxiv.org/abs/2303.15446)
"introduce a novel efficient additive attention mechanism"

## 2022
### A-ViT Adaptive Tokens for Efficient Vision Transformer CVPR 2022 [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Yin_A-ViT_Adaptive_Tokens_for_Efficient_Vision_Transformer_CVPR_2022_paper.html) [[code]](https://github.com/NVlabs/A-ViT)
### MaxViT Multi-Axis Vision Transformer ECCV [[arXiv paper]](https://arxiv.org/abs/2204.01697) [[code]](https://github.com/google-research/maxvit) [[timm code]](https://github.com/rwightman/pytorch-image-models)
### MetaFormer Baselines for Vision arXiv 2022
### Temporally Efficient Vision Transformer for Video Instance Segmentation CVPR 2022 [[paper]](https://openaccess.thecvf.com/content/CVPR2022/html/Yang_Temporally_Efficient_Vision_Transformer_for_Video_Instance_Segmentation_CVPR_2022_paper.html) [[code]](https://github.com/hustvl/TeViT)
### Vision Transformer with Deformable Attention CVPR 2022
### What Makes for Good Tokenizers in Vision Transformer arXiv 2022 [[arXiv paper]](https://arxiv.org/abs/2212.11115)

## 2021
### (UN-EPT) A Unified Efficient Pyramid Transformer for Semantic Segmentation arXiv 2021 [[arXiv paper]](https://arxiv.org/abs/2107.14209)
### CoAtNet Marrying Convolution and Attention for All Data Sizes [[arXiv paper]](https://arxiv.org/abs/2106.04803) [[timm code]](https://github.com/rwightman/pytorch-image-models)
### CSWin Transformer A General Vision Transformer Backbone with Cross-Shaped Windows arXiv 2021 [[arXiv paper]](https://arxiv.org/abs/2107.00652) [[code]](https://github.com/microsoft/CSWin-Transformer)
### DS-TransUNet Dual Swin Transformer U-Net for Medical Image Segmentation arXiv 2021 [[paper]]()
### P2T Pyramid Pooling Transformer for Scene Understanding arXiv 2021 [[paper]]()
### PVTv2 Improved Baselines with Pyramid Vision Transformer arXiv 2021 [[paper]]()
### Swin Transformer Hierarchical Vision Transformer Using Shifted Windows ICCV 2021 [[paper]]()

## 2019
### Axial Attention in Multidimensional Transformers arXiv 2019 [[arXiv paper]](https://arxiv.org/abs/1912.12180)
